{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMINlXzjJJSH"
   },
   "source": [
    "# Redes Neurais em PLN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descrição\n",
    "Aplicar redes neurais em tarefas de classificação de texto usando técnicas de PLN, utilizando a biblitoeca TensorFlow para construção de modelos. As técnicas envolvem vetorização dos textos com métodos como Tokenizer e padronização com pad_sequences, além da criação e treino de modelos de rede neural para prever sentimentos ou categorias de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycF-LKg_VDAW"
   },
   "source": [
    "## Implementação 1: Modelo de Rede Neural de Recorrência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHYQDCgRNGJ-"
   },
   "source": [
    "### Passo 1: Configuração do Ambiente no Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16569,
     "status": "ok",
     "timestamp": 1749859727940,
     "user": {
      "displayName": "Victor Myke Gracioli Rocha",
      "userId": "18280186660482340267"
     },
     "user_tz": 180
    },
    "id": "f0RTOVrxhdVc",
    "outputId": "dc63a010-4135-4af3-d0be-faf7b6fb633b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "print(\"Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1CS8SwPN2_d"
   },
   "source": [
    "Explicação:\n",
    "*   numpy: Para operações numéricas.\n",
    "*   tensorflow.keras: A API de alto nível para construir e treinar modelos de deep learning.\n",
    "*   Embedding: camada que transforma palavras (indices numéricos) em vetores densos.\n",
    "*   SimpleRNN: A camada de Rede Neural recorrente mais básica.\n",
    "*   Dense: Camada neural comum (fully connected layer).\n",
    "*   Tokenizer: Para converter texto em sequências de números.\n",
    "*   pad_sequences: Para garantir que todas as sequências de entrada tenham o mesmo comprimento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y--LE1jcQAOt"
   },
   "source": [
    "### Passo 2: Preparação do Conjunto de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1749859736209,
     "user": {
      "displayName": "Victor Myke Gracioli Rocha",
      "userId": "18280186660482340267"
     },
     "user_tz": 180
    },
    "id": "N5ojTgQlQJRl",
    "outputId": "4bd4d605-41d0-4f56-d8be-72aa27ab294d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textos de treinamento: ['eu gosto de programar em python', 'python é uma linguagem poderosa', 'programar é divertido com python', 'aprenda python e seja feliz', 'gosto de aprender coisas novas']\n"
     ]
    }
   ],
   "source": [
    "# Conjunto de dados de treinamento (pequeno e simplificado)\n",
    "textos_treinamento = [\n",
    "    \"eu gosto de programar em python\",\n",
    "    \"python é uma linguagem poderosa\",\n",
    "    \"programar é divertido com python\",\n",
    "    \"aprenda python e seja feliz\",\n",
    "    \"gosto de aprender coisas novas\",\n",
    "]\n",
    "print(f\"Textos de treinamento: {textos_treinamento}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1749859767941,
     "user": {
      "displayName": "Victor Myke Gracioli Rocha",
      "userId": "18280186660482340267"
     },
     "user_tz": 180
    },
    "id": "v9krczj_RC89",
    "outputId": "5677a2a1-5612-43a0-fc02-eb7f7075632e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulário (palavra: índice): {'python': 1, 'gosto': 2, 'de': 3, 'programar': 4, 'é': 5, 'eu': 6, 'em': 7, 'uma': 8, 'linguagem': 9, 'poderosa': 10, 'divertido': 11, 'com': 12, 'aprenda': 13, 'e': 14, 'seja': 15, 'feliz': 16, 'aprender': 17, 'coisas': 18, 'novas': 19}\n",
      "Sequências numéricas dos textos: [[6, 2, 3, 4, 7, 1], [1, 5, 8, 9, 10], [4, 5, 11, 12, 1], [13, 1, 14, 15, 16], [2, 3, 17, 18, 19]]\n",
      "Tamanho total do vocabulário: 20\n"
     ]
    }
   ],
   "source": [
    "# Inicializar o Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Construir o vocabulário a partir dos textos\n",
    "tokenizer.fit_on_texts(textos_treinamento)\n",
    "\n",
    "# Converter textos em sequências de números\n",
    "sequencias = tokenizer.texts_to_sequences(textos_treinamento)\n",
    "\n",
    "# Imprimir o vocabulário e as sequências geradas\n",
    "print(f\"\\nVocabulário (palavra: índice): {tokenizer.word_index}\")\n",
    "print(f\"Sequências numéricas dos textos: {sequencias}\")\n",
    "\n",
    "# Calcular o tamanho do vocabulário (+1 para incluir o 0 de padding)\n",
    "total_palavras = len(tokenizer.word_index) + 1\n",
    "print(f\"Tamanho total do vocabulário: {total_palavras}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1749859951983,
     "user": {
      "displayName": "Victor Myke Gracioli Rocha",
      "userId": "18280186660482340267"
     },
     "user_tz": 180
    },
    "id": "SsTz57WmSZrO",
    "outputId": "e658286d-9cdc-42f6-ffb0-49a28a1ae051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comprimento máximo das sequências antes do padding: 6\n",
      "Exemplo de entradas_x (parcial): [[6], [6, 2], [6, 2, 3], [6, 2, 3, 4], [6, 2, 3, 4, 7]]\n",
      "Exemplo de saidas_y (parcial): [2, 3, 4, 7, 1]\n",
      "\n",
      "Exemplo de entradas_x_padded (após padding e truncagem): \n",
      "[[0 0 0 0 6]\n",
      " [0 0 0 6 2]\n",
      " [0 0 6 2 3]\n",
      " [0 6 2 3 4]\n",
      " [6 2 3 4 7]]\n",
      "Exemplo de saidas_y_one_hot (após one-hot encoding): \n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Formato final das entradas (x): (21, 5)\n",
      "Formato final das saídas (y): (21, 20)\n"
     ]
    }
   ],
   "source": [
    "# Preparar Entradas (x) e Saídas (y) para aprevisão da próxima palavra\n",
    "# a entrada (x) será uma sequência de palavras, e a saída (y) será a palavra seguinte.\n",
    "# Determinar o comprimento máximo das sequências para padding\n",
    "max_comprimento = max(len(seq) for seq in sequencias)\n",
    "print(f\"\\nComprimento máximo das sequências antes do padding: {max_comprimento}\")\n",
    "\n",
    "# Criar pares de entrada (sequência parcial) e saida (próxima palavra)\n",
    "# Ex: \"eu gosto de programar\" -> \"em\"\n",
    "#     \"gosto de programar em\" -> \"python\"\n",
    "entradas_x = []\n",
    "saidas_y = []\n",
    "\n",
    "for seq in sequencias:\n",
    "    for i in range(1, len(seq)):\n",
    "        entradas_x.append(seq[:i]) # A sequência até a palavra atual\n",
    "        saidas_y.append(seq[i])    # A próxima palavra\n",
    "\n",
    "print(f\"Exemplo de entradas_x (parcial): {entradas_x[0:5]}\")\n",
    "print(f\"Exemplo de saidas_y (parcial): {saidas_y[0:5]}\")\n",
    "\n",
    "# Padronizar o comprimento das sequências de entrada\n",
    "# Todas as seuências de entrada precisam ter o mesmo comprimento para a RNN\n",
    "entradas_X_padded = pad_sequences(entradas_x, maxlen=max_comprimento -1, padding='pre')\n",
    "# O maxlen é `max_comprimento -1` porque saída `y` é a última palavra, então X sempre terá 1 palavra a menos.\n",
    "\n",
    "# Converter as saídas para o formato one-hot encoding\n",
    "# Isso é necessário para a camada de saída da RNN (softmax)\n",
    "saidas_Y_one_hot = tf.keras.utils.to_categorical(saidas_y, num_classes=total_palavras)\n",
    "\n",
    "print(f\"\\nExemplo de entradas_x_padded (após padding e truncagem): \\n{entradas_X_padded[0:5]}\")\n",
    "print(f\"Exemplo de saidas_y_one_hot (após one-hot encoding): \\n{saidas_Y_one_hot[0:5]}\")\n",
    "print(f\"Formato final das entradas (x): {entradas_X_padded.shape}\")\n",
    "print(f\"Formato final das saídas (y): {saidas_Y_one_hot.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyrpTzQmi8vV"
   },
   "source": [
    "Explicação:\n",
    "\n",
    "\n",
    "*   Geração de Pares (Sequência -> Próxima palavra): Para treinar a RNN a prever a próxima palavra, transformamos cada frase em multiplos pares de (sequência parcial, próxima palavra).\n",
    "*   pad_sequences: É vital. Como as sequências parciais têm comprimentos variados, pad_sequences preenche (com zeros, por padrão) as sequências mais curtas para que todas tenham o mesmo maxlen. O padding='pre' significa que os zeros são adicionados no inicio.\n",
    "*   to_categorical: A camada de saida da RNN (com softmax) produz uma probabilidade para cada palavra no vocabulário. to_categorical converte o indice da palavra real em um vetor onde apenas a posição da palavra correta é 1 e o resto é 0 (chamado de one-hot encoding).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HH8PsPOJrLdF"
   },
   "source": [
    "### Passo 3: Construção do Modelo RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1749860050681,
     "user": {
      "displayName": "Victor Myke Gracioli Rocha",
      "userId": "18280186660482340267"
     },
     "user_tz": 180
    },
    "id": "CrZKNcLmrK12",
    "outputId": "3d1d7649-d170-483e-c053-b628f6f1c399"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\antho\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Definindo o modelo\n",
    "# Definir a arquitetura do modelo RNN\n",
    "modelo_rnn = Sequential()\n",
    "\n",
    "# Camada de Embedding:\n",
    "# total_palavras: tamanho do vocabulário\n",
    "# 10: dimensão do vetor de embedding (quantas características queremos para cada palavra)\n",
    "# input_length: comprimento das sequências de entrada (maxlen - 1)\n",
    "modelo_rnn.add(Embedding(total_palavras, 10, input_length=entradas_X_padded.shape[1]))\n",
    "\n",
    "# Camada SimpleRNN:\n",
    "# 32: número de unidades (neurônios) na camada recorrente. Este é o tamanho de estado oculto.\n",
    "modelo_rnn.add(SimpleRNN(32))\n",
    "\n",
    "# Camada Densa de Saída:\n",
    "# total_palavras: número de neurônios de saída (um para cada palavra no vocabulário)\n",
    "# activation = 'softmax': função de ativação para probabilidade (soma 1 para todas as palavras)\n",
    "modelo_rnn.add(Dense(total_palavras, activation='softmax'))\n",
    "\n",
    "# Compilar o modelo\n",
    "modelo_rnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Imprimir a arquitetura do modelo\n",
    "modelo_rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWwUMkPHkwKZ"
   },
   "source": [
    "Explicação da Arquitetura:\n",
    "\n",
    "*   Embedding Layer: Essencial em PLN. Ela mapeia cada palavra (representada por seu indice numérico) para um vetor denso de embedding. Este vetor captura relações semânticas entre as palavras. Por Exemplo, palavras com significados semelhantes estarão \"próximas\" no espaço de embedding.\n",
    "*   SampleRNN Layer: Esta é a camada recorrente. Ela recebe as sequências de embeddings e processa-as passo a passo. O 32 indica a dimensão do vetor de estado oculto (ou seja, a \"memória\" que a RNN carrega ao longo do tempo).\n",
    "*   Dense (Output) Layer: Esta camadafinal recebe o estado oculto final da SimpleRNN e o transforma em um vetor de probabilidades, onde cada posição corresponde a uma palavra do vocabulário, A função softmax garante que a soma dessas probabilidades seja 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1vRIyfCuBL2"
   },
   "source": [
    "### Passo 4: Treinamento de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10664,
     "status": "ok",
     "timestamp": 1749860194148,
     "user": {
      "displayName": "Victor Myke Gracioli Rocha",
      "userId": "18280186660482340267"
     },
     "user_tz": 180
    },
    "id": "Jbmem62SCSLr",
    "outputId": "227aac64-584d-4b1f-92f2-ff2ec0b84a15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando o treinamento do modelo RNN...\n",
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.0476 - loss: 2.9927\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0952 - loss: 2.9840\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.0476 - loss: 2.9755\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1429 - loss: 2.9670\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1429 - loss: 2.9586\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.1429 - loss: 2.9502\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.1429 - loss: 2.9416\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1429 - loss: 2.9330\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.1905 - loss: 2.9242\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1905 - loss: 2.9152\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.1905 - loss: 2.9059\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1905 - loss: 2.8964\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.1905 - loss: 2.8867\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.1905 - loss: 2.8767\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.1905 - loss: 2.8663\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1905 - loss: 2.8556\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.1905 - loss: 2.8446\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1905 - loss: 2.8333\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1905 - loss: 2.8217\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1905 - loss: 2.8097\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1905 - loss: 2.7975\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.1905 - loss: 2.7849\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1905 - loss: 2.7721\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.1905 - loss: 2.7590\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1905 - loss: 2.7457\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.1905 - loss: 2.7321\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.1905 - loss: 2.7183\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2381 - loss: 2.7043\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2381 - loss: 2.6901\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.2381 - loss: 2.6756\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.2381 - loss: 2.6610\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2381 - loss: 2.6462\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1905 - loss: 2.6312\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1429 - loss: 2.6159\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1429 - loss: 2.6005\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.1429 - loss: 2.5847\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.1429 - loss: 2.5687\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1429 - loss: 2.5524\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.1429 - loss: 2.5356\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1429 - loss: 2.5185\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1429 - loss: 2.5009\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1429 - loss: 2.4827\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.1429 - loss: 2.4641\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.1429 - loss: 2.4448\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1429 - loss: 2.4250\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1429 - loss: 2.4047\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.2381 - loss: 2.3837\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2857 - loss: 2.3622\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.3333 - loss: 2.3402\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3333 - loss: 2.3177\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3333 - loss: 2.2947\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3810 - loss: 2.2713\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.3810 - loss: 2.2474\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3810 - loss: 2.2232\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.3333 - loss: 2.1987\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3333 - loss: 2.1738\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3333 - loss: 2.1486\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3333 - loss: 2.1231\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3333 - loss: 2.0975\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.3333 - loss: 2.0717\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3810 - loss: 2.0457\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4762 - loss: 2.0196\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4762 - loss: 1.9935\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4762 - loss: 1.9673\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4762 - loss: 1.9411\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4286 - loss: 1.9150\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4762 - loss: 1.8889\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.4762 - loss: 1.8628\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5238 - loss: 1.8369\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5238 - loss: 1.8110\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6190 - loss: 1.7853\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6190 - loss: 1.7597\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6190 - loss: 1.7342\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6190 - loss: 1.7088\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6190 - loss: 1.6836\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6190 - loss: 1.6586\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6190 - loss: 1.6337\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6190 - loss: 1.6090\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6190 - loss: 1.5845\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7143 - loss: 1.5601\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7619 - loss: 1.5360\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7619 - loss: 1.5121\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7619 - loss: 1.4885\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7619 - loss: 1.4650\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7619 - loss: 1.4418\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7619 - loss: 1.4189\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7143 - loss: 1.3962\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7143 - loss: 1.3737\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7143 - loss: 1.3516\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7143 - loss: 1.3297\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7143 - loss: 1.3080\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7143 - loss: 1.2867\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7619 - loss: 1.2656\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7619 - loss: 1.2448\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7619 - loss: 1.2243\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8095 - loss: 1.2041\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8095 - loss: 1.1842\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8095 - loss: 1.1645\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8095 - loss: 1.1452\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8095 - loss: 1.1261\n",
      "Treinamento concluido!\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo\n",
    "print(\"\\nIniciando o treinamento do modelo RNN...\")\n",
    "modelo_rnn.fit(entradas_X_padded, saidas_Y_one_hot, epochs=100, verbose=1)\n",
    "    # epochs: quantas vezes o modelo verá todo o conjunto de dados\n",
    "    # verbose: 1 para mostrar o proggresso do treinamento\n",
    "print(\"Treinamento concluido!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRb52ef3vfse"
   },
   "source": [
    "### Passo 5: Usar o Modelo para Previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 737,
     "status": "ok",
     "timestamp": 1749860246081,
     "user": {
      "displayName": "Victor Myke Gracioli Rocha",
      "userId": "18280186660482340267"
     },
     "user_tz": 180
    },
    "id": "KTIQdpiRvl72",
    "outputId": "e27e8500-ac19-4630-f2bb-ddd77af396d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testando o Modelo RNN ---\n",
      "Texto: 'eu gosto de' -> Próxima palavra prevista: 'programar'\n",
      "Texto: 'python é uma' -> Próxima palavra prevista: 'linguagem'\n",
      "Texto: 'programar é divertido' -> Próxima palavra prevista: 'com'\n",
      "Texto: 'aprenda python e' -> Próxima palavra prevista: 'seja'\n",
      "Texto: 'o sol brilha no' -> Próxima palavra prevista: 'de'\n"
     ]
    }
   ],
   "source": [
    "# 1. Função de Previsão:\n",
    "def prever_proxima_palavra(modelo, tokenizer, max_seq_len, texto_base):\n",
    "  \"\"\"\n",
    "  Prevê a próxima palavra dado um texto base.\n",
    "  \"\"\"\n",
    "  # Converter o texto base para sequência numárica\n",
    "  sequencia_numerica = tokenizer.texts_to_sequences([texto_base])[0]\n",
    "\n",
    "\n",
    "  # Padronizar o comprimento da sequência de entrada (precisa ter o mesmo formato que p treinamento)\n",
    "  # Atenção: max_seq_len deve ser o comprimento que as \"entradas\" foram pad_sequenciadas\n",
    "  sequencia_padded = pad_sequences([sequencia_numerica], maxlen=max_seq_len, padding='pre')\n",
    "\n",
    "  # Fazer a previsão\n",
    "  previsao_probabilidades = modelo.predict(sequencia_padded, verbose=0)[0]\n",
    "\n",
    "  # Obter o índice da palavra com a maior probabilidade\n",
    "  indice_palavra_prevista = np.argmax(previsao_probabilidades)\n",
    "\n",
    "  # Converter o índice de volta para a palavra\n",
    "  for palavra, indice in tokenizer.word_index.items():\n",
    "    if indice == indice_palavra_prevista:\n",
    "      return palavra\n",
    "  return None # Caso a palavra não seja encontrada (improvável com o vocabulário ajustado)\n",
    "\n",
    "# Comprimento de entrada esperando pelo modelo\n",
    "# entradas_x_padded.shape[1] é o maxlen que usamos no pad_sequences para x\n",
    "comprimento_entrada_modelo = entradas_X_padded.shape[1]\n",
    "\n",
    "# Testar o modelo com novas frases\n",
    "print(\"\\n--- Testando o Modelo RNN ---\")\n",
    "\n",
    "texto_teste_1 = \"eu gosto de\"\n",
    "proxima_1 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_1)\n",
    "print(f\"Texto: '{texto_teste_1}' -> Próxima palavra prevista: '{proxima_1}'\")\n",
    "\n",
    "texto_teste_2 = \"python é uma\"\n",
    "proxima_2 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_2)\n",
    "print(f\"Texto: '{texto_teste_2}' -> Próxima palavra prevista: '{proxima_2}'\")\n",
    "\n",
    "texto_teste_3 = \"programar é divertido\"\n",
    "proxima_3 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_3)\n",
    "print(f\"Texto: '{texto_teste_3}' -> Próxima palavra prevista: '{proxima_3}'\")\n",
    "\n",
    "texto_teste_4 = \"aprenda python e\"\n",
    "proxima_4 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_4)\n",
    "print(f\"Texto: '{texto_teste_4}' -> Próxima palavra prevista: '{proxima_4}'\")\n",
    "\n",
    "# Exemplo com palavra fora do vocabulário (ou sequência que o modelo nunca viu antes)\n",
    "texto_teste_5 = \"o sol brilha no\"\n",
    "proxima_5 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_5)\n",
    "print(f\"Texto: '{texto_teste_5}' -> Próxima palavra prevista: '{proxima_5}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_47id0SFxe6"
   },
   "source": [
    "## Implementação 2: Modelo de Rede Neural Rede Long Short-Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2-PIqToGDyS"
   },
   "source": [
    "### Passo 1: Configuração do Ambiente e Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2148,
     "status": "ok",
     "timestamp": 1749860415124,
     "user": {
      "displayName": "Victor Myke Gracioli Rocha",
      "userId": "18280186660482340267"
     },
     "user_tz": 180
    },
    "id": "bjYs9pZLAEkr",
    "outputId": "d3711486-e161-47e5-9545-6b2e3c96649f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPPYQOcfHJPS"
   },
   "source": [
    "O que tem de novo aqui?\n",
    "\n",
    "*   LSTM: A camada de Rede Long Short-Term Memory.\n",
    "*   train_test_split (sklearn): Paradividiro dataset em conjuntos de treinamentoe teste.\n",
    "*   classification_report, confusion_matrix (sklearn): Para avaliar o desempenho do modelo.\n",
    "*   matplotlib.pyplot, seaborn: Para visualização dos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgDWCrKbH_eJ"
   },
   "source": [
    "### Passo 2: Preparação do Conjunto de Dados de Análise de Sentimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1749860582643,
     "user": {
      "displayName": "Victor Myke Gracioli Rocha",
      "userId": "18280186660482340267"
     },
     "user_tz": 180
    },
    "id": "on7jEnQjIW7Z",
    "outputId": "105a5adc-75cc-420d-a7b8-c2d4e1e372c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases: 15\n",
      "Exemplo de textos: ['este filme é ótimo e divertido', 'eu adorei o livro, muito bom', 'gostei muito da atuação dos atores']\n",
      "Exemplo de sentimentos: ['positivo', 'positivo', 'positivo']\n"
     ]
    }
   ],
   "source": [
    "# Definir o Conjunto de Dados (Frames e Rótulos) para análise de sentimentos\n",
    "dados_sentimento = [\n",
    "    (\"este filme é ótimo e divertido\",\"positivo\"),\n",
    "    (\"eu adorei o livro, muito bom\",\"positivo\"),\n",
    "    (\"gostei muito da atuação dos atores\",\"positivo\"),\n",
    "    (\"o roteiro é fraco e chato\",\"negativo\"),\n",
    "    (\"não recomendo este péssimo produto\",\"negativo\"),\n",
    "    (\"uma perda de tempo horrível\",\"negativo\"),\n",
    "    (\"ótimo trabalho, parabéns\",\"positivo\"),\n",
    "    (\"terrível experiência, nunca mais\",\"negativo\"),\n",
    "    (\"excelente serviço, muito eficiente\",\"positivo\"),\n",
    "    (\"que decepção, muito ruim\",\"negativo\"),\n",
    "    (\"aprendizagem de máquina é fascinante\",\"positivo\"),\n",
    "    (\"pln é um campo interessante\",\"positivo\"),\n",
    "    (\"este software travou várias vezes\",\"negativo\"),\n",
    "    (\"a interface é confusa e difícil\",\"negativo\"),\n",
    "    (\"o aplicativo é super útil e rápido\",\"positivo\"),\n",
    "]\n",
    "\n",
    "textos = [dado[0] for dado in dados_sentimento]\n",
    "sentimentos = [dado[1] for dado in dados_sentimento]\n",
    "\n",
    "print(f\"Total de frases: {len(textos)}\")\n",
    "print(f\"Exemplo de textos: {textos[:3]}\")\n",
    "print(f\"Exemplo de sentimentos: {sentimentos[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1749860737076,
     "user": {
      "displayName": "Victor Myke Gracioli Rocha",
      "userId": "18280186660482340267"
     },
     "user_tz": 180
    },
    "id": "0qKDlyz3RqSZ",
    "outputId": "801f0ea0-bd79-45cb-e651-3a28871092b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentimentos mapeados para números: [1 1 1 0 0 0 1 0 1 0 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Mapear Sentimentos para Números: converter \"positivo\" e \"negativo\" para 0 e 1\n",
    "mapeamento_sentimento = {'negativo': 0, 'positivo':1}\n",
    "rotulos_numericos = np.array([mapeamento_sentimento[s] for s in sentimentos])\n",
    "\n",
    "print(f\"\\nSentimentos mapeados para números: {rotulos_numericos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1749860745403,
     "user": {
      "displayName": "Victor Myke Gracioli Rocha",
      "userId": "18280186660482340267"
     },
     "user_tz": 180
    },
    "id": "C-bWESbQRt7A",
    "outputId": "ab2295a9-f20f-407a-bc83-917f1adb532e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulário (palavra: índice): {'<unk>': 1, 'é': 2, 'e': 3, 'muito': 4, 'este': 5, 'o': 6, 'ótimo': 7, 'de': 8, 'filme': 9, 'divertido': 10, 'eu': 11, 'adorei': 12, 'livro': 13, 'bom': 14, 'gostei': 15, 'da': 16, 'atuação': 17, 'dos': 18, 'atores': 19, 'roteiro': 20, 'fraco': 21, 'chato': 22, 'não': 23, 'recomendo': 24, 'péssimo': 25, 'produto': 26, 'uma': 27, 'perda': 28, 'tempo': 29, 'horrível': 30, 'trabalho': 31, 'parabéns': 32, 'terrível': 33, 'experiência': 34, 'nunca': 35, 'mais': 36, 'excelente': 37, 'serviço': 38, 'eficiente': 39, 'que': 40, 'decepção': 41, 'ruim': 42, 'aprendizagem': 43, 'máquina': 44, 'fascinante': 45, 'pln': 46, 'um': 47, 'campo': 48, 'interessante': 49, 'software': 50, 'travou': 51, 'várias': 52, 'vezes': 53, 'a': 54, 'interface': 55, 'confusa': 56, 'difícil': 57, 'aplicativo': 58, 'super': 59, 'útil': 60, 'rápido': 61}\n",
      "Sequências numéricas das palavras: [[5, 9, 2, 7, 3, 10], [11, 12, 6, 13, 4, 14], [15, 4, 16, 17, 18, 19], [6, 20, 2, 21, 3, 22], [23, 24, 5, 25, 26], [27, 28, 8, 29, 30], [7, 31, 32], [33, 34, 35, 36], [37, 38, 4, 39], [40, 41, 4, 42], [43, 8, 44, 2, 45], [46, 2, 47, 48, 49], [5, 50, 51, 52, 53], [54, 55, 2, 56, 3, 57], [6, 58, 2, 59, 60, 3, 61]]\n",
      "Total de palavras no vocabulário: 62\n",
      "\n",
      "Comprimento máximo das sequências: 7\n",
      "Sequências após padding: \n",
      "[[ 5  9  2  7  3 10  0]\n",
      " [11 12  6 13  4 14  0]\n",
      " [15  4 16 17 18 19  0]\n",
      " [ 6 20  2 21  3 22  0]\n",
      " [23 24  5 25 26  0  0]\n",
      " [27 28  8 29 30  0  0]\n",
      " [ 7 31 32  0  0  0  0]\n",
      " [33 34 35 36  0  0  0]\n",
      " [37 38  4 39  0  0  0]\n",
      " [40 41  4 42  0  0  0]\n",
      " [43  8 44  2 45  0  0]\n",
      " [46  2 47 48 49  0  0]\n",
      " [ 5 50 51 52 53  0  0]\n",
      " [54 55  2 56  3 57  0]\n",
      " [ 6 58  2 59 60  3 61]]\n",
      "\n",
      "Shape de x_treino: (12, 7)\n",
      "Shape de x_teste: (3, 7)\n",
      "Shape de y_treino: (12,)\n",
      "Shape de y_teste: (3,)\n"
     ]
    }
   ],
   "source": [
    "# Tokenização de Texto\n",
    "tokenizer = Tokenizer(num_words=None, oov_token=\"<unk>\")\n",
    "  # num_words=None para pegar todo o vacubulário\n",
    "  # oov_token para palavras desconhecidas\n",
    "tokenizer.fit_on_texts(textos)\n",
    "sequencias_numericas = tokenizer.texts_to_sequences(textos)\n",
    "\n",
    "total_palavras_vocab = len(tokenizer.word_index) + 1 # +1 para o 0 de padding/oov\n",
    "\n",
    "print(f\"\\nVocabulário (palavra: índice): {tokenizer.word_index}\")\n",
    "print(f\"Sequências numéricas das palavras: {sequencias_numericas}\")\n",
    "print(f\"Total de palavras no vocabulário: {total_palavras_vocab}\")\n",
    "\n",
    "# Padronizar o comprimento das sequências\n",
    "# Encontrar o comprimento da frase mais longa para padronizar\n",
    "max_len = max(len(s) for s in sequencias_numericas)\n",
    "print(f\"\\nComprimento máximo das sequências: {max_len}\")\n",
    "\n",
    "sequencias_padded = pad_sequences(sequencias_numericas, maxlen=max_len, padding='post') # 'post' para adicionar zeros no final\n",
    "print(f\"Sequências após padding: \\n{sequencias_padded}\")\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(\n",
    "    sequencias_padded, rotulos_numericos, test_size=0.2, random_state=42,stratify=rotulos_numericos\n",
    "    )\n",
    "\n",
    "print(f\"\\nShape de x_treino: {x_treino.shape}\")\n",
    "print(f\"Shape de x_teste: {x_teste.shape}\")\n",
    "print(f\"Shape de y_treino: {y_treino.shape}\")\n",
    "print(f\"Shape de y_teste: {y_teste.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KojbdT_dm4G8"
   },
   "source": [
    "### Passo 3: Construção do Modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "executionInfo": {
     "elapsed": 122,
     "status": "ok",
     "timestamp": 1749860808360,
     "user": {
      "displayName": "Victor Myke Gracioli Rocha",
      "userId": "18280186660482340267"
     },
     "user_tz": 180
    },
    "id": "2AJAzQGGl85t",
    "outputId": "2818a907-9f28-4d57-d118-fcd815cb531d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\antho\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir a arquitetura do modelo LSTM\n",
    "modelo_lstm = Sequential()\n",
    "\n",
    "# Camada de Embedding: Converte os índices numéricos das palavras em vetores densos.\n",
    "# total_palavras_vocab: tamanho do vocabulário\n",
    "# 50: dimensão do vetor de embedding (pode ser ajustado)\n",
    "# input_length: comprimento padronizado das sequências (max_len)\n",
    "modelo_lstm.add(Embedding(total_palavras_vocab, 50, input_length=max_len))\n",
    "\n",
    "# Camada LSTM:\n",
    "# 64: número de unidades (neurônios) na camada LSTM. Define o tamanho do estado oculto e da célula de memória.\n",
    "# dropou: Um tipo de regularização para evitar overfitting (descarta aleatoriamenteneurônios durante o treinamento).\n",
    "# recurrent_dropout: Dropout aplicado nas conexões recorrentes da LSTM.\n",
    "modelo_lstm.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "# Camada Densa de Saída:\n",
    "# 1: Um único neurônio de saída, pois é um problema de classificação binária (positivo/negativo).\n",
    "# activation='sigmoid': Função de ativação para classificação binária (produz um valor entre 0 e 1).\n",
    "modelo_lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilar o modelo\n",
    "modelo_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Exibir um resumo da arquitetura do modelo\n",
    "modelo_lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPyNCONQrmc0"
   },
   "source": [
    "### Paso 4: Treinamento e Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15747,
     "status": "ok",
     "timestamp": 1749860878820,
     "user": {
      "displayName": "Victor Myke Gracioli Rocha",
      "userId": "18280186660482340267"
     },
     "user_tz": 180
    },
    "id": "_cM6m0DGrzfT",
    "outputId": "abaeffb3-f2bc-4742-baa0-e57c0b75cf3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando o treinamento do modelo LSTM...\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5000 - loss: 0.6926 - val_accuracy: 0.5000 - val_loss: 0.6927\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7000 - loss: 0.6915 - val_accuracy: 0.5000 - val_loss: 0.6928\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7000 - loss: 0.6914 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9000 - loss: 0.6893 - val_accuracy: 0.0000e+00 - val_loss: 0.6935\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9000 - loss: 0.6875 - val_accuracy: 0.0000e+00 - val_loss: 0.6939\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.8000 - loss: 0.6897 - val_accuracy: 0.0000e+00 - val_loss: 0.6942\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9000 - loss: 0.6821 - val_accuracy: 0.0000e+00 - val_loss: 0.6945\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9000 - loss: 0.6821 - val_accuracy: 0.0000e+00 - val_loss: 0.6949\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.8000 - loss: 0.6805 - val_accuracy: 0.0000e+00 - val_loss: 0.6953\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.9000 - loss: 0.6757 - val_accuracy: 0.0000e+00 - val_loss: 0.6958\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.6741 - val_accuracy: 0.0000e+00 - val_loss: 0.6964\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.6690 - val_accuracy: 0.0000e+00 - val_loss: 0.6970\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9000 - loss: 0.6634 - val_accuracy: 0.0000e+00 - val_loss: 0.6977\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.6608 - val_accuracy: 0.0000e+00 - val_loss: 0.6986\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.6555 - val_accuracy: 0.0000e+00 - val_loss: 0.6997\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 0.6452 - val_accuracy: 0.0000e+00 - val_loss: 0.7011\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.6394 - val_accuracy: 0.0000e+00 - val_loss: 0.7029\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.6241 - val_accuracy: 0.0000e+00 - val_loss: 0.7050\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.6190 - val_accuracy: 0.0000e+00 - val_loss: 0.7076\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.6048 - val_accuracy: 0.0000e+00 - val_loss: 0.7108\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.5919 - val_accuracy: 0.0000e+00 - val_loss: 0.7147\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.5752 - val_accuracy: 0.0000e+00 - val_loss: 0.7194\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.5643 - val_accuracy: 0.0000e+00 - val_loss: 0.7251\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.5386 - val_accuracy: 0.0000e+00 - val_loss: 0.7321\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.5109 - val_accuracy: 0.0000e+00 - val_loss: 0.7406\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.4974 - val_accuracy: 0.0000e+00 - val_loss: 0.7509\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.4664 - val_accuracy: 0.0000e+00 - val_loss: 0.7636\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.4089 - val_accuracy: 0.0000e+00 - val_loss: 0.7791\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.4083 - val_accuracy: 0.0000e+00 - val_loss: 0.7980\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.3812 - val_accuracy: 0.0000e+00 - val_loss: 0.8211\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.3366 - val_accuracy: 0.0000e+00 - val_loss: 0.8493\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.2786 - val_accuracy: 0.0000e+00 - val_loss: 0.8838\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.2441 - val_accuracy: 0.0000e+00 - val_loss: 0.9257\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.2157 - val_accuracy: 0.0000e+00 - val_loss: 0.9768\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.1787 - val_accuracy: 0.0000e+00 - val_loss: 1.0386\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.1455 - val_accuracy: 0.0000e+00 - val_loss: 1.1127\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.1180 - val_accuracy: 0.0000e+00 - val_loss: 1.2007\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.1094 - val_accuracy: 0.0000e+00 - val_loss: 1.3046\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 0.0705 - val_accuracy: 0.0000e+00 - val_loss: 1.4236\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0694 - val_accuracy: 0.0000e+00 - val_loss: 1.5586\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.0482 - val_accuracy: 0.0000e+00 - val_loss: 1.7077\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0363 - val_accuracy: 0.0000e+00 - val_loss: 1.8682\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.0301 - val_accuracy: 0.0000e+00 - val_loss: 2.0368\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0208 - val_accuracy: 0.0000e+00 - val_loss: 2.2091\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.0197 - val_accuracy: 0.0000e+00 - val_loss: 2.3827\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.0000e+00 - val_loss: 2.5548\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.0000e+00 - val_loss: 2.7226\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.0000e+00 - val_loss: 2.8837\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.0000e+00 - val_loss: 3.0372\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.0000e+00 - val_loss: 3.1823\n",
      "Treinamento concluído!\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo\n",
    "print(\"\\nIniciando o treinamento do modelo LSTM...\")\n",
    "historico = modelo_lstm.fit(\n",
    "    x_treino, y_treino,\n",
    "    epochs=50, # Reduzi para 50 epochs para um treinamento mais rápido no  exemplo. Pode ser aumentado.\n",
    "    batch_size=32, # Pequeno batch_size para dataset pequeno.\n",
    "    validation_split=0.1, # Usar 10% do treino para validação\n",
    "    verbose=1\n",
    ")\n",
    "    # epochs: número de vezes que o modelo verá todo o conjunto de dados de treinamento.\n",
    "    # batch_size: número de amostras por atualização de gradiente\n",
    "    # validation_split: % dos dados de treino usados para validação durante o treinamento (opcional, mas bom para monitorar overfitting).\n",
    "print(\"Treinamento concluído!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 767
    },
    "executionInfo": {
     "elapsed": 1238,
     "status": "ok",
     "timestamp": 1749860896886,
     "user": {
      "displayName": "Victor Myke Gracioli Rocha",
      "userId": "18280186660482340267"
     },
     "user_tz": 180
    },
    "id": "pfAnL803uVt8",
    "outputId": "23ea9c95-c6e8-4890-9e50-51785f0c7e5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acurácia do modelo no conjunto de teste: 66.67%\n",
      "Perda do modelo no conjunto de teste: 0.5516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
      "\n",
      "--- Relátório de Classificação ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.50      1.00      0.67         1\n",
      "    positivo       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.75      0.75      0.67         3\n",
      "weighted avg       0.83      0.67      0.67         3\n",
      "\n",
      "\n",
      "--- Matriz de Confusão ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Avalia o modelo no conjunto de teste\n",
    "perda, acuracia = modelo_lstm.evaluate(x_teste, y_teste, verbose=0)\n",
    "print(f\"\\nAcurácia do modelo no conjunto de teste: {acuracia*100:.2f}%\")\n",
    "print(f\"Perda do modelo no conjunto de teste: {perda:.4f}\")\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred_prob = modelo_lstm.predict(x_teste)\n",
    "y_pred_classes = (y_pred_prob > 0.5).astype(int) # Converter probabilidades para 0 ou 1\n",
    "\n",
    "print(\"\\n--- Relátório de Classificação ---\")\n",
    "print(classification_report(y_teste, y_pred_classes, target_names=['negativo','positivo']))\n",
    "\n",
    "print(\"\\n--- Matriz de Confusão ---\")\n",
    "cm = confusion_matrix(y_teste, y_pred_classes)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',xticklabels=['negativo','positivo'], yticklabels=['negativo','positivo'])\n",
    "plt.xlabel('Previsto')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJMVgu4Ox4Vj"
   },
   "source": [
    "### Passo 5: Testar o Modelo com Novas Frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 793,
     "status": "ok",
     "timestamp": 1749861183492,
     "user": {
      "displayName": "Victor Myke Gracioli Rocha",
      "userId": "18280186660482340267"
     },
     "user_tz": 180
    },
    "id": "4g3xakFmx9yC",
    "outputId": "8c4fda7f-a402-4fb4-ff20-8612f9605668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testando o Modelo LSTM com Novas Frases ---\n",
      "Frase: 'gostei muito de filme, excelente!' -> Sentimento previsto: 'positivo'\n",
      "Frase: 'odiei o livro, muito entediante' -> Sentimento previsto: 'positivo'\n",
      "Frase: 'a aula de pln é ótima' -> Sentimento previsto: 'positivo'\n",
      "Frase: 'o atendimento foi péssimo' -> Sentimento previsto: 'negativo'\n",
      "Frase: 'esse produto não vale a pena, é caro' -> Sentimento previsto: 'negativo'\n",
      "Frase: 'o filme é legal' -> Sentimento previsto: 'positivo'\n",
      "Frase: 'isso é horrível, que tristeza' -> Sentimento previsto: 'negativo'\n"
     ]
    }
   ],
   "source": [
    "from re import VERBOSE\n",
    "# utilizando o modelo treinado\n",
    "def prever_sentimento(modelo, tokenizer, max_seq_len, frase_nova, mapeamento_sentimento):\n",
    "  \"\"\"\n",
    "  Prevê o sentimento de uma nova frase.\n",
    "  \"\"\"\n",
    "  # Converter a frase para sequência numérica\n",
    "  sequencia_numerica = tokenizer.texts_to_sequences([frase_nova])\n",
    "\n",
    "  # Se a frase tem palavras desconhecidas, o tokenizer retorna uma lista vazia ou valores 0\n",
    "  if not sequencia_numerica:\n",
    "    print(f\"Aviso: A frase '{frase_nova}' contém apenas palavras desconhecidas.\")\n",
    "    return \"Desconhecido\" # Ou outra indicação\n",
    "\n",
    "  sequencia_numerica = sequencia_numerica [0] # Pega a primeira (e única) sequência\n",
    "\n",
    "  # Padronizar o comprimento da sequência de entrada\n",
    "  sequencia_padded = pad_sequences([sequencia_numerica], maxlen=max_seq_len, padding='post')\n",
    "\n",
    "  # Fazer a previsão (probabilidade)\n",
    "  probabilidade_positiva = modelo.predict(sequencia_padded, verbose=0)[0][0]\n",
    "\n",
    "  # Inverter o mapeamento para obter o nome do sentimento\n",
    "  mapeamento_inverso = {v: k for k, v in mapeamento_sentimento.items()}\n",
    "\n",
    "  # Classificar com base no limiar de 0.5\n",
    "  if probabilidade_positiva >= 0.5:\n",
    "    return mapeamento_inverso[1] # 'positivo'\n",
    "  else:\n",
    "    return mapeamento_inverso[0] # 'negativo'\n",
    "\n",
    "  return sentimento_previsto\n",
    "\n",
    "# Testar o modelo com novas frases\n",
    "print(\"\\n--- Testando o Modelo LSTM com Novas Frases ---\")\n",
    "\n",
    "frase_nova_1 = \"gostei muito de filme, excelente!\"\n",
    "sentimento_1 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_1, mapeamento_sentimento)\n",
    "print(f\"Frase: '{frase_nova_1}' -> Sentimento previsto: '{sentimento_1}'\")\n",
    "\n",
    "frase_nova_2 = \"odiei o livro, muito entediante\"\n",
    "sentimento_2 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_2, mapeamento_sentimento)\n",
    "print(f\"Frase: '{frase_nova_2}' -> Sentimento previsto: '{sentimento_2}'\")\n",
    "\n",
    "frase_nova_3 = \"a aula de pln é ótima\"\n",
    "sentimento_3 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_3, mapeamento_sentimento)\n",
    "print(f\"Frase: '{frase_nova_3}' -> Sentimento previsto: '{sentimento_3}'\")\n",
    "\n",
    "frase_nova_4 = \"o atendimento foi péssimo\"\n",
    "sentimento_4 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_4, mapeamento_sentimento)\n",
    "print(f\"Frase: '{frase_nova_4}' -> Sentimento previsto: '{sentimento_4}'\")\n",
    "\n",
    "frase_nova_5 = \"esse produto não vale a pena, é caro\"\n",
    "sentimento_5 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_5, mapeamento_sentimento)\n",
    "print(f\"Frase: '{frase_nova_5}' -> Sentimento previsto: '{sentimento_5}'\")\n",
    "\n",
    "frase_nova_6 = \"o filme é legal\" # Frase curta e ambígua para um modelo pequeno\n",
    "sentimento_6 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_6, mapeamento_sentimento)\n",
    "print(f\"Frase: '{frase_nova_6}' -> Sentimento previsto: '{sentimento_6}'\")\n",
    "\n",
    "frase_nova_7 = \"isso é horrível, que tristeza\"\n",
    "sentimento_7 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_7, mapeamento_sentimento)\n",
    "print(f\"Frase: '{frase_nova_7}' -> Sentimento previsto: '{sentimento_7}'\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOgemUPBgrK2M2TrksjOR1h",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
